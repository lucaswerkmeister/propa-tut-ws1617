\documentclass{beamer}
\usepackage{tut}

\def\tuttitle{C, MPI}
\date{2017-01-23/24}

\begin{document}
\normalsize
\normalem

\lstset{language=C}

\begin{frame}[plain]
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{Nachtrag}
  “song4” vom letzten Mal war übrigens die KIT-Hymne.
\end{frame}

\begin{frame}
  \frametitle{C: Zeiger-Arithmetik, Arrays}
  Welche Ausgabe erzeugt das folgende C-Programm?
  \lstinputlisting[linerange={1-1,3-15}]{tut10/task1.c}
\end{frame}

\begin{frame}[fragile]
  \frametitle{(c)gdb Spickzettel}
  Wichtige Befehle:
  \begin{description}\let\realitem=\item \renewcommand{\item}[1][]{\realitem[\textbf#1]}
  \item[break] Breakpoint setzen
  \item[run] Programm starten
  \item[step] Programm einen Schritt weiterlaufen lassen
  \item[next] Programm einen Schritt weiterlaufen lassen,
    dabei Funktionsaufrufe überspringen
  \item[print] Ausdruck auswerten und Ergebnis anzeigen
  \item[continue] Programm weiterlaufen lassen
  \item[list] Code an der aktuellen Stelle anzeigen lassen
  \end{description}
\end{frame}

\begin{frame}[fragile]
  \frametitle{MPI: Punkt-zu-Punkt-Kommunikation}
  Eine Firma entwickelt folgendes MPI-Programm,
  welches dafür vorgesehen ist, von zwei MPI-Prozessen ausgeführt zu werden.

  Während des Testens durch die Firma verhält sich das Programm wie erwartet.
  Nach der Auslieferung beschweren sich die Kunden jedoch prompt darüber, dass das Programm hängenbleibt.

  \begin{enumerate}
  \item Wieso bleibt das Programm hängen?
  \item Finde möglichst viele Lösungen, das Programm zu verändern, so dass es korrekt funktioniert.
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{MPI: Punkt-zu-Punkt-Kommunikation}
  \lstinputlisting[linerange={6-7,9-22,24-27}]{tut10/task2.c}
\end{frame}

\begin{frame}
  \frametitle{MPI: Punkt-zu-Punkt-Kommunikation – 1}
  Das Programm bleibt hängen, weil beide Prozesse zunächst \lstinline{MPI_Send} und dann \lstinline{MPI_Recv} aufrufen.
  Wenn der \lstinline{MPI_Send}-Aufruf blockiert, bis die Übertragung durch \lstinline{MPI_Recv} am anderen Ende stattfinden kann,
  dann warten beide Prozesse darauf, dass der jeweils andere \lstinline{MPI_Recv} aufruft, ohne dies jedoch selbst zu tun.
  
  Beim Testen in der Firma wurde offenbar eine andere MPI-Implementierung verwendet,
  welche im Standardmodus puffert, d.\,h., \lstinline{MPI_Send} überträgt die Daten in einen Puffer,
  danach geht die Ausführung allerdings weiter, ohne auf \lstinline{MPI_Recv} zu warten.
\end{frame}

\begin{frame}
  \frametitle{MPI: Punkt-zu-Punkt-Kommunikation – 2}
  \begin{itemize}
  \item Kreis aufbrechen:
    Ein Prozess ruft \lstinline{MPI_Recv} vor \lstinline{MPI_Send} auf.
  \item Explizit puffern:
    Puffer mit \lstinline{MPI_Buffer_attach} bereitstellen,
    \lstinline{MPI_Bsend} verwenden.
  \item Asynchron senden:
    \lstinline{MPI_ISend} verwenden.
    Wichtig: anderen Puffer für \lstinline{MPI_Recv} verwenden –
    der Puffer für \lstinline{MPI_Isend} darf nicht verändert werden, bis die Übertragung abgeschlossen ist!
  \item Sende- und Empfangsoperation kombinieren:
    \lstinline{MPI_Sendrecv} oder \lstinline{MPI_Sendrecv_replace} verwenden.
  \item …
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{MPI: Reduce}
  Analysiere folgendes MPI-Programm, welches mit 4 Prozessen ausgeführt wird.
  Welche Werte enthalten \lstinline{sendbuffer} und \lstinline{recvbuffer} am Ende?
  \lstinputlisting[linerange={9-21}]{tut10/task3-1.c}
\end{frame}

\begin{frame}
  \frametitle{MPI: Reduce}
  \begin{table}
    \begin{tabular}{r|l l l l}
      \lstinline{sendbuffer} bei Rank 0 &       0 & 1 & 2 & 3 \\
      \lstinline{sendbuffer} bei Rank 1 &       1 & 2 & 3 & 4\\
      \lstinline{sendbuffer} bei Rank 2 &       2 & 3 & 4 & 5 \\
      \lstinline{sendbuffer} bei Rank 3 &       3 & 4 & 5 & 6 \\
      \lstinline{recvbuffer} bei Rank 0 &\pause 6 & 10 & 14 & 18 \\
    \end{tabular}
  \end{table}
\end{frame}

\begin{frame}[fragile]
  \frametitle{MPI: Reduce – \lstinline{my_int_sum_reduce}}
  Implementiere mit Hilfe von \lstinline{MPI_Send}, \lstinline{MPI_Recv}, \lstinline{MPI_Comm_size} und \lstinline{MPI_Comm_rank} folgende Funktion:
  \lstinputlisting[linerange={3-4}]{tut10/task3-2-sol.c}
  Die folgenden Aufrufe sollen dabei gleichbedeutend sein:
  \begin{lstlisting}
    my_int_sum_reduce(sendbuf, recvbuf, count,
                      root, comm);
    MPI_Reduce(sendbuf, recvbuf, count,
               MPI_INT, MPI_SUM,
               root, comm);
  \end{lstlisting}
  
  \textbf{Hinweis:} Fehlerbehandlung unnötig; Aufrufe von \lstinline{MPI_Send} mit gleichem Sender und Empfänger vermeiden.
\end{frame}

\begin{frame}
  \frametitle{MPI: Reduce – \lstinline{my_int_sum_reduce}}
  \lstinputlisting[linerange={6-24}]{tut10/task3-2-sol.c}
\end{frame}

\begin{frame}[fragile]
  \frametitle{MPI: Scatter \& Allgather}
  In einem Aufruf
  \begin{lstlisting}
    int MPI_Scatter(void *sbuf, int scount, MPI_Datatype styp,
                    void *rbuf, int rcount, MPI_Datatype rtyp,
                    int root, MPI_Comm comm)
  \end{lstlisting}
  bestimmt \lstinline{scount}, wie viele Elemente an jeden einzelnen Prozess in \lstinline{comm} gesendet werden.
  
  Im folgenden Programmstück seien \lstinline{buf_1} und \lstinline{buf_2} hinreichend große Puffer, \lstinline{k} $≥2$ und \lstinline{c} die Anzahl an Prozessen in \lstinline{comm}.
  \begin{lstlisting}
    MPI_Scatter  (buf_1, k, MPI_INT,
                  buf_2, k, MPI_INT,
                  0, comm);
    MPI_Allgather(buf_2, k, MPI_INT,
                  buf_1, k, MPI_INT,
                     comm);
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile]
  \frametitle{MPI: Scatter \& Allgather}
  \begin{enumerate}
  \item Welche Daten stehen nach Ausführung dieses Programmstücks in den Puffern der einzelnen Prozesse?
    \begin{itemize}
    \item
      In \lstinline{buf_2} steht\only<1>{…}\onslide<2->{ in Prozess $p_j$ der Inhalt des Bereichs $j \cdot k$ bis $(j+1) \cdot k - 1$ von $p_0$s \lstinline{buf_1}.}
    \item
      In \lstinline{buf_1} steht\only<1-2>{…}\onslide<3->{ für jeden Prozess die Konkatenation der \lstinline{buf_2} aller Prozesse,
      also der ursprüngliche Inhalt von $p_0$s \lstinline{buf_1}.}
    \end{itemize}
  \item Ersetze die beiden Aufrufe \lstinline{MPI_Scatter} und \lstinline{MPI_Allgather} durch einen Aufruf einer MPI-Methode,
    so dass \lstinline{buf_1} danach den gleichen Inhalt hat.
    \pause[4]
    \begin{lstlisting}
      MPI_Bcast(buf_1, c*k, MPI_INT, 0, comm);
    \end{lstlisting}
  \end{enumerate}
\end{frame}

\end{document}
